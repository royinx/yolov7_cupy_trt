{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pycuda cupy-cuda11x pynvjpeg line_profiler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "img = cv2.imread('/py/crop/9/3.jpg')\n",
    "\n",
    "pinned_memory_pool = cp.cuda.PinnedMemoryPool()\n",
    "cp.cuda.set_pinned_memory_allocator(pinned_memory_pool.malloc)\n",
    "\n",
    "\n",
    "def _pin_memory(array):\n",
    "    mem = cp.cuda.alloc_pinned_memory(array.nbytes)\n",
    "    ret = np.frombuffer(mem, array.dtype, array.size).reshape(array.shape)\n",
    "    ret[...] = array\n",
    "    return ret\n",
    "\n",
    "# SIZE = 1920 * 1080 *3\n",
    "# x_cpu_src = np.arange(SIZE, dtype=np.uint8)\n",
    "x_cpu_src = cv2.imread('/py/crop/9/3.jpg')\n",
    "print(x_cpu_src.shape,x_cpu_src.size)\n",
    "x_gpu_src = cp.arange(x_cpu_src.size, dtype=np.uint8).reshape(x_cpu_src.shape)\n",
    "\n",
    "# # synchronous\n",
    "# stream = cp.cuda.Stream.null\n",
    "# start = stream.record()\n",
    "# x_gpu_dst = cp.empty(x_cpu_src.shape, x_cpu_src.dtype)\n",
    "# x_gpu_dst.set(x_cpu_src)\n",
    "# x_cpu_dst = x_gpu_src.get()\n",
    "# end = stream.record()\n",
    "\n",
    "# print('Synchronous Device to Host / Host to Device (ms)')\n",
    "# print(cp.cuda.get_elapsed_time(start, end))\n",
    "\n",
    "# asynchronous\n",
    "x_gpu_dst = cp.empty(x_cpu_src.shape, x_cpu_src.dtype)\n",
    "x_cpu_dst = np.empty(x_gpu_src.shape, x_gpu_src.dtype)\n",
    "\n",
    "x_pinned_cpu_src = _pin_memory(x_cpu_src)\n",
    "x_pinned_cpu_dst = _pin_memory(x_cpu_dst)\n",
    "\n",
    "with cp.cuda.stream.Stream() as stream_htod:\n",
    "    start = stream_htod.record()\n",
    "    x_gpu_dst.set(x_pinned_cpu_src)\n",
    "    with cp.cuda.stream.Stream() as stream_dtoh:\n",
    "        x_gpu_src.get(out=x_pinned_cpu_dst)\n",
    "        stream_dtoh.synchronize()\n",
    "    stream_htod.synchronize()\n",
    "    end = stream_htod.record()\n",
    "\n",
    "print('Asynchronous Device to Host / Host to Device (ms)')\n",
    "print(cp.cuda.get_elapsed_time(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asynchronous Host to Device (ms)\n",
      "0.09881599992513657\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cupy as cp\n",
    "from nvjpeg import NvJpeg\n",
    "\n",
    "nj = NvJpeg()\n",
    "img_host = nj.read('/py/crop/9/3.jpg') \n",
    "\n",
    "pinned_memory_pool = cp.cuda.PinnedMemoryPool()\n",
    "cp.cuda.set_pinned_memory_allocator(pinned_memory_pool.malloc)\n",
    "\n",
    "def _pin_memory(array):\n",
    "    device_mem = cp.cuda.alloc_pinned_memory(array.nbytes)\n",
    "    ret = np.frombuffer(device_mem, array.dtype, array.size).reshape(array.shape)\n",
    "    ret[...] = array\n",
    "    return ret\n",
    "\n",
    "img_device = cp.empty(img_host.shape, img_host.dtype)\n",
    "img_pinned_host = _pin_memory(img_host)\n",
    "\n",
    "with cp.cuda.stream.Stream() as stream_htod:\n",
    "    start = stream_htod.record()\n",
    "    img_device.set(img_pinned_host)\n",
    "    stream_htod.synchronize()\n",
    "    end = stream_htod.record()\n",
    "print('Asynchronous Host to Device (ms)')\n",
    "print(cp.cuda.get_elapsed_time(start, end))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from nvjpeg import NvJpeg\n",
    "# from line_profiler import LineProfiler\n",
    "\n",
    "# nj = NvJpeg()\n",
    "# profile = LineProfiler()\n",
    "\n",
    "# @profile\n",
    "# def inner_nj():\n",
    "#     img = nj.read('/py/crop/9/3.jpg')\n",
    "#     nj_jpg = nj.encode(img)\n",
    "    \n",
    "# @profile\n",
    "# def inner_cv2():\n",
    "#     img = cv2.imread('/py/crop/9/3.jpg')\n",
    "#     cv2_jpg = cv2.imencode('.jpg',img)[1]\n",
    "\n",
    "# for _ in range(1000):\n",
    "#     inner_nj()\n",
    "#     inner_cv2()\n",
    "# profile.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 27 22:18:49 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 31%   32C    P2    54W / 300W |    380MiB / 11016MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin   cuda-11\t cuda-11.4  games    lib  mpi  sbin   src\r\n",
      "cuda  cuda-11.3  etc\t    include  man  nvm  share  ucx\r\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "YOLOv7ONNXandTRT.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
